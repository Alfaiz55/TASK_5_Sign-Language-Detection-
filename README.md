# Sign Language Detection (NullClass Internship Task 5)

## ğŸ“Œ Project Overview
This project is part of the NullClass Internship.  
The goal is to build a **Sign Language Detection system** that can recognize selected sign language gestures from both **images and real-time video input**.  
The application is designed to run only between **6 PM and 10 PM**, as per the task requirements.  

## ğŸš€ Features
- Detects and classifies sign language gestures.
- Works with both **image upload** and **real-time webcam feed**.
- Time restriction: only functions between **6:00 PM â€“ 10:00 PM**.
- User-friendly **GUI** built with Python.

## ğŸ› ï¸ Tech Stack
- **Python 3.10**
- **TensorFlow / Keras** (model training & prediction)
- **OpenCV** (real-time video capture & image processing)
- **Tkinter** (GUI development)
- **NumPy, Pandas, Matplotlib** (data handling and visualization)

## ğŸ“‚ Project Structure
Task5_SignLanguageDetection/
â”‚â”€â”€ app.py # GUI Application
â”‚â”€â”€ sign_language_model.keras # Trained Model
â”‚â”€â”€ sign_language_detection.ipynb # Training Notebook
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md # Project Documentation


## âš™ï¸ Installation & Setup
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/SignLanguageDetection.git
   cd SignLanguageDetection

ğŸ“Š Dataset
The model was trained on publicly available Sign Language datasets.
(Dataset source: Mention Kaggle/official dataset link here)

ğŸ¯ Output
Upload an image or start real-time video capture.
The GUI will display the predicted sign if run during the allowed time (6 PM â€“ 10 PM).

ğŸ‘¨â€ğŸ’» Internship Details
Internship Provider: NullClass
Task: Task 5 â€“ Sign Language Detection
Requirement: GUI-based system with time restrictions

âœ… Submission Checklist
 Model file (.keras)
 Training Notebook (.ipynb)
 GUI script (app.py)
 Requirements file (requirements.txt)
 README file (README.md)

âœï¸ Developed as part of the NullClass Internship Program.
